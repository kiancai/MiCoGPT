{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ea28bc",
   "metadata": {},
   "source": [
    "## 1. 提取 csv 的第一列的 taxonomy 信息\n",
    "\n",
    "- 提取了 n 个 taxonomic 信息，则后续就会在 SILVA 数据库中查询这 n 个 taxonomic 信息是否存在\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d021e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    k__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
      "1    k__Bacteria;p__Bdellovibrionota;c__Bdellovibri...\n",
      "2    k__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
      "3    k__Bacteria;p__Firmicutes;c__Clostridia;o__Eub...\n",
      "4    k__Bacteria;p__Proteobacteria;c__Gammaproteoba...\n",
      "Name: Taxonomy, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH=\"/Users/kiancai/STA24/CWD/STAi/MiCoGPT/data/try2_withCC/abundance_all_90338.csv\"\n",
    "\n",
    "df = pd.read_csv(PATH)\n",
    "first_column = df.iloc[:, 0]\n",
    "\n",
    "# 保存为 full_taxonomy.csv\n",
    "first_column.to_csv(\"full_taxonomy.csv\", index=False)\n",
    "print(first_column[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b512d36",
   "metadata": {},
   "source": [
    "## 2. check match 的情况\n",
    "\n",
    "- 检查 SILVA 数据库中是否有对应的 taxonomic 信息，以及每个 taxonomic 信息查询到的对应的 SILVA 数据库中代表序列的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90fed423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每个 genus 在 SILVA 中匹配到的行数：\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Genus\n",
       "g__Bacillus             12014\n",
       "g__Pseudomonas           7070\n",
       "g__Streptomyces          5809\n",
       "g__Streptococcus         4635\n",
       "g__Staphylococcus        4443\n",
       "                        ...  \n",
       "g__Peptoanaerobacter        2\n",
       "g__Gulbenkiania             2\n",
       "g__Faucicola                1\n",
       "g__Jonquetella              1\n",
       "g__Oceanotoga               1\n",
       "Length: 1117, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 物种情况\n",
    "csv_path = \"full_taxonomy.csv\"\n",
    "tax_df = pd.read_csv(csv_path)\n",
    "tax_df.columns = [\"Taxonomy\"]\n",
    "\n",
    "# silva 的物种情况\n",
    "silva_tax_path = \"data/silva-138-99-tax-exported/taxonomy.tsv\"\n",
    "silva_df = pd.read_csv(silva_tax_path, sep=\"\\t\")\n",
    "\n",
    "# 匹配 genus\n",
    "tax_df[\"Genus\"] = tax_df[\"Taxonomy\"].str.extract(r\"(g__[^;]+)\")\n",
    "silva_df[\"Genus\"] = silva_df[\"Taxon\"].str.extract(r\"(g__[^;]+)\")\n",
    "\n",
    "# 丢弃没有匹配到的\n",
    "query_genera = tax_df[\"Genus\"].dropna().unique()\n",
    "silva_sub = silva_df[silva_df[\"Genus\"].isin(query_genera)].copy()\n",
    "\n",
    "genus_counts = (\n",
    "    silva_sub\n",
    "    .groupby(\"Genus\")\n",
    "    .size()\n",
    "    .sort_values(ascending=False)\n",
    ")\n",
    "\n",
    "print(\"每个 genus 在 SILVA 中匹配到的行数：\")\n",
    "display(genus_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf762240",
   "metadata": {},
   "source": [
    "## 3. Tokenization\n",
    "\n",
    "- 一次性对匹配到的所有序列进行 tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbccc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "/home/cml_lab/anaconda3/envs/caiqy_DNABERT_S/lib/python3.9/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "/home/cml_lab/caiqy/.cache/huggingface/modules/transformers_modules/zhihan1996/DNABERT-S/00e47f96cdea35e4b6f5df89e5419cbe47d490c6/bert_layers.py:126: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型真正的最大 token 长度（max_position_embeddings）： 512\n",
      "tokenizer.model_max_length（仅供参考，可能是占位值）： 1000000000000000019884624838656\n",
      "总序列数量: 264926\n",
      "FASTA 加载数量: 436680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing: 100%|███████████████████████████████████████| 264926/264926 [00:01<00:00, 146082.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization 完成！\n",
      "被截断的序列数量： 23\n",
      "所有序列中最长的 token 长度： 732\n",
      "Token 文件保存到 tokens.npz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from Bio import SeqIO\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "# 1. 加载 tokenizer 和 model（CPU），获取真实 max_len\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"zhihan1996/DNABERT-S\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    \"zhihan1996/DNABERT-S\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "max_len = model.config.max_position_embeddings\n",
    "print(\"模型真正的最大 token 长度（max_position_embeddings）：\", max_len)\n",
    "\n",
    "\n",
    "# 2. 读取 SILVA 子集和 FASTA\n",
    "N = silva_sub.shape[0]\n",
    "print(\"需要 embedding 的总序列数量:\", N)\n",
    "\n",
    "fasta_path = \"data/silva-138-99-seqs-exported/dna-sequences.fasta\"\n",
    "seq_dict = {r.id: str(r.seq) for r in SeqIO.parse(fasta_path, \"fasta\")}\n",
    "print(\"SILVA 中包含的 FASTA 总量:\", len(seq_dict))\n",
    "\n",
    "\n",
    "\n",
    "# 3. 单条序列的 tokenization\n",
    "def tokenize_one(args):\n",
    "    idx, fid, genus = args\n",
    "    seq = seq_dict[fid]\n",
    "\n",
    "    tokens = tokenizer(\n",
    "        seq,\n",
    "        return_tensors=\"np\",\n",
    "        truncation=False,\n",
    "        padding=False\n",
    "    )[\"input_ids\"][0]   # shape=(L,)\n",
    "\n",
    "    token_len = len(tokens)\n",
    "    truncated = token_len > max_len\n",
    "\n",
    "    return idx, fid, genus, tokens, token_len, truncated\n",
    "\n",
    "\n",
    "\n",
    "# 4. 多线程 tokenizer（32 线程可改）\n",
    "THREADS = 32\n",
    "\n",
    "# 注意：这里我们按 idx 存，保证和 silva_sub 一一对应\n",
    "token_arrays = [None] * N\n",
    "token_lengths = np.zeros(N, dtype=np.int32)\n",
    "feature_ids = np.empty(N, dtype=object)\n",
    "genera = np.empty(N, dtype=object)\n",
    "truncated_flags = np.zeros(N, dtype=np.uint8)\n",
    "\n",
    "jobs = [(i, row[\"Feature ID\"], row[\"Genus\"]) for i, (_, row) in enumerate(silva_sub.iterrows())]\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=THREADS) as executor:\n",
    "    futures = [executor.submit(tokenize_one, j) for j in jobs]\n",
    "\n",
    "    for f in tqdm(as_completed(futures), total=N, desc=\"Tokenizing\", ncols=100):\n",
    "        idx, fid, genus, tokens, token_len, truncated = f.result()\n",
    "\n",
    "        token_arrays[idx] = tokens\n",
    "        token_lengths[idx] = token_len\n",
    "        feature_ids[idx] = fid\n",
    "        genera[idx] = genus\n",
    "        truncated_flags[idx] = truncated\n",
    "\n",
    "print(\"Tokenization 完成！\")\n",
    "print(\"被截断的序列数量：\", int(truncated_flags.sum()))\n",
    "\n",
    "# 统计最长的 token 序列长度\n",
    "max_token_len = int(token_lengths.max())\n",
    "print(\"所有序列中最长的 token 长度：\", max_token_len)\n",
    "\n",
    "# 你如果想顺便看一下长度分布，也可以加一个简单统计：\n",
    "# print(\"token length 分位数：\", np.percentile(token_lengths, [50, 90, 95, 99]))\n",
    "\n",
    "\n",
    "# 5. 保存结果（NPZ）\n",
    "np.savez_compressed(\n",
    "    \"tokens.npz\",\n",
    "    token_arrays=np.array(token_arrays, dtype=object),\n",
    "    token_lengths=token_lengths,\n",
    "    feature_ids=feature_ids,\n",
    "    genera=genera,\n",
    "    truncated=truncated_flags\n",
    ")\n",
    "\n",
    "print(\"Token 文件保存到 tokens.npz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6998f50",
   "metadata": {},
   "source": [
    "## 4. filter \n",
    "\n",
    "- 由于上一步，部分 taxonomic 信息在 SILVA 数据库中的全长序列进行 tokenization 后，得到的 tokenized 序列长度超过了 DNABERT-S 的最大输入长度（512），因此需要对这些序列进行过滤。又由于 DNABERT-S 采用了 BPE，所以只有在进行了 tokenized 以后我们才可能知道到底哪些序列长度会超出 512。因此，我们需要对 tokenized 后的序列进行过滤，只保留长度小于等于 512 的序列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c1badb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总序列数: 264926\n",
      "被标记为截断的序列数: 23\n",
      "\n",
      "=== 所有被截断的序列（共 23 条） ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Genus</th>\n",
       "      <th>FeatureID</th>\n",
       "      <th>TokenLength</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37545</th>\n",
       "      <td>37545</td>\n",
       "      <td>g__Streptococcus</td>\n",
       "      <td>CAQA01000070.1409.4877</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37844</th>\n",
       "      <td>37844</td>\n",
       "      <td>g__Streptococcus</td>\n",
       "      <td>CIIB01000023.4139.7040</td>\n",
       "      <td>615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37847</th>\n",
       "      <td>37847</td>\n",
       "      <td>g__Streptococcus</td>\n",
       "      <td>CKGV01000033.4234.7508</td>\n",
       "      <td>663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38293</th>\n",
       "      <td>38293</td>\n",
       "      <td>g__Mycoplasma</td>\n",
       "      <td>CP001047.191404.193931</td>\n",
       "      <td>523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38616</th>\n",
       "      <td>38616</td>\n",
       "      <td>g__Thermus</td>\n",
       "      <td>CP001962.592399.595224</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39053</th>\n",
       "      <td>39053</td>\n",
       "      <td>g__Corynebacterium</td>\n",
       "      <td>CP002857.115758.118576</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40387</th>\n",
       "      <td>40387</td>\n",
       "      <td>g__Bacillus</td>\n",
       "      <td>CP008712.321643.324759</td>\n",
       "      <td>631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41291</th>\n",
       "      <td>41291</td>\n",
       "      <td>g__Bacillus</td>\n",
       "      <td>CP010106.282981.285881</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42084</th>\n",
       "      <td>42084</td>\n",
       "      <td>g__Staphylococcus</td>\n",
       "      <td>CP012409.2263835.2266601</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49659</th>\n",
       "      <td>49659</td>\n",
       "      <td>g__Streptococcus</td>\n",
       "      <td>CRPA01000007.15140.18272</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71341</th>\n",
       "      <td>71341</td>\n",
       "      <td>g__Sellimonas</td>\n",
       "      <td>EU009803.1.2917</td>\n",
       "      <td>617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96715</th>\n",
       "      <td>96715</td>\n",
       "      <td>g__Streptococcus</td>\n",
       "      <td>FIRE01000004.97119.99950</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109883</th>\n",
       "      <td>109883</td>\n",
       "      <td>g__Neisseria</td>\n",
       "      <td>FJ876273.1.2633</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112756</th>\n",
       "      <td>112756</td>\n",
       "      <td>g__Staphylococcus</td>\n",
       "      <td>FMPP01000014.85987.89090</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119626</th>\n",
       "      <td>119626</td>\n",
       "      <td>g__Treponema</td>\n",
       "      <td>FR749928.1.3062</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148089</th>\n",
       "      <td>148089</td>\n",
       "      <td>g__Succinivibrionaceae_UCG-001</td>\n",
       "      <td>HQ399845.1.3026</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159316</th>\n",
       "      <td>159316</td>\n",
       "      <td>g__Mycobacterium</td>\n",
       "      <td>JAOC01000010.934431.937439</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168781</th>\n",
       "      <td>168781</td>\n",
       "      <td>g__Ureaplasma</td>\n",
       "      <td>JF731007.1.3023</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239348</th>\n",
       "      <td>239348</td>\n",
       "      <td>g__Candidatus_Jorgensenbacteria</td>\n",
       "      <td>KX123380.1.2523</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239350</th>\n",
       "      <td>239350</td>\n",
       "      <td>g__Candidatus_Adlerbacteria</td>\n",
       "      <td>KX123388.1.2322</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252975</th>\n",
       "      <td>252975</td>\n",
       "      <td>g__Staphylococcus</td>\n",
       "      <td>LN610139.1.2752</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253935</th>\n",
       "      <td>253935</td>\n",
       "      <td>g__Micrococcus</td>\n",
       "      <td>LS483396.118448.121363</td>\n",
       "      <td>639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254967</th>\n",
       "      <td>254967</td>\n",
       "      <td>g__Methanobrevibacter</td>\n",
       "      <td>LWMW01000084.19615.22720</td>\n",
       "      <td>621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           idx                            Genus                   FeatureID  \\\n",
       "37545    37545                 g__Streptococcus      CAQA01000070.1409.4877   \n",
       "37844    37844                 g__Streptococcus      CIIB01000023.4139.7040   \n",
       "37847    37847                 g__Streptococcus      CKGV01000033.4234.7508   \n",
       "38293    38293                    g__Mycoplasma      CP001047.191404.193931   \n",
       "38616    38616                       g__Thermus      CP001962.592399.595224   \n",
       "39053    39053               g__Corynebacterium      CP002857.115758.118576   \n",
       "40387    40387                      g__Bacillus      CP008712.321643.324759   \n",
       "41291    41291                      g__Bacillus      CP010106.282981.285881   \n",
       "42084    42084                g__Staphylococcus    CP012409.2263835.2266601   \n",
       "49659    49659                 g__Streptococcus    CRPA01000007.15140.18272   \n",
       "71341    71341                    g__Sellimonas             EU009803.1.2917   \n",
       "96715    96715                 g__Streptococcus    FIRE01000004.97119.99950   \n",
       "109883  109883                     g__Neisseria             FJ876273.1.2633   \n",
       "112756  112756                g__Staphylococcus    FMPP01000014.85987.89090   \n",
       "119626  119626                     g__Treponema             FR749928.1.3062   \n",
       "148089  148089   g__Succinivibrionaceae_UCG-001             HQ399845.1.3026   \n",
       "159316  159316                 g__Mycobacterium  JAOC01000010.934431.937439   \n",
       "168781  168781                    g__Ureaplasma             JF731007.1.3023   \n",
       "239348  239348  g__Candidatus_Jorgensenbacteria             KX123380.1.2523   \n",
       "239350  239350      g__Candidatus_Adlerbacteria             KX123388.1.2322   \n",
       "252975  252975                g__Staphylococcus             LN610139.1.2752   \n",
       "253935  253935                   g__Micrococcus      LS483396.118448.121363   \n",
       "254967  254967            g__Methanobrevibacter    LWMW01000084.19615.22720   \n",
       "\n",
       "        TokenLength  \n",
       "37545           732  \n",
       "37844           615  \n",
       "37847           663  \n",
       "38293           523  \n",
       "38616           617  \n",
       "39053           609  \n",
       "40387           631  \n",
       "41291           596  \n",
       "42084           573  \n",
       "49659           660  \n",
       "71341           617  \n",
       "96715           602  \n",
       "109883          559  \n",
       "112756          644  \n",
       "119626          648  \n",
       "148089          643  \n",
       "159316          662  \n",
       "168781          630  \n",
       "239348          533  \n",
       "239350          513  \n",
       "252975          584  \n",
       "253935          639  \n",
       "254967          621  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 每个 Genus 的总序列数（前几行预览） ===\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Genus\n",
       "g__Bacillus          12014\n",
       "g__Pseudomonas        7070\n",
       "g__Streptomyces       5809\n",
       "g__Streptococcus      4635\n",
       "g__Staphylococcus     4443\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 删除计划统计 ===\n",
      "被截断序列总数:            23\n",
      "计划删除的截断序列条数:    23\n",
      "计划保留但仍被截断的条数:  0\n",
      "\n",
      "=== 各 Genus 的截断情况与删除计划 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cml_lab/tmp/ipykernel_19680/2743670463.py:72: FutureWarning: Pinning the groupby key to each group in SeriesGroupBy.agg is deprecated, and cases that relied on it will raise in a future version. If your operation requires utilizing the groupby keys, iterate over the groupby object instead.\n",
      "  trunc_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TotalInGenus</th>\n",
       "      <th>TruncCount</th>\n",
       "      <th>DropCount</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genus</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g__Streptococcus</th>\n",
       "      <td>4635</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Staphylococcus</th>\n",
       "      <td>4443</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Bacillus</th>\n",
       "      <td>12014</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Candidatus_Adlerbacteria</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Methanobrevibacter</th>\n",
       "      <td>961</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Micrococcus</th>\n",
       "      <td>295</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Candidatus_Jorgensenbacteria</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Corynebacterium</th>\n",
       "      <td>2945</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Mycoplasma</th>\n",
       "      <td>573</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Mycobacterium</th>\n",
       "      <td>1186</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Sellimonas</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Neisseria</th>\n",
       "      <td>924</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Succinivibrionaceae_UCG-001</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Thermus</th>\n",
       "      <td>174</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Treponema</th>\n",
       "      <td>1315</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>g__Ureaplasma</th>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 TotalInGenus  TruncCount  DropCount\n",
       "Genus                                                               \n",
       "g__Streptococcus                         4635           5          5\n",
       "g__Staphylococcus                        4443           3          3\n",
       "g__Bacillus                             12014           2          2\n",
       "g__Candidatus_Adlerbacteria                34           1          1\n",
       "g__Methanobrevibacter                     961           1          1\n",
       "g__Micrococcus                            295           1          1\n",
       "g__Candidatus_Jorgensenbacteria            10           1          1\n",
       "g__Corynebacterium                       2945           1          1\n",
       "g__Mycoplasma                             573           1          1\n",
       "g__Mycobacterium                         1186           1          1\n",
       "g__Sellimonas                              32           1          1\n",
       "g__Neisseria                              924           1          1\n",
       "g__Succinivibrionaceae_UCG-001             28           1          1\n",
       "g__Thermus                                174           1          1\n",
       "g__Treponema                             1315           1          1\n",
       "g__Ureaplasma                              91           1          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "过滤后总序列数: 264903\n",
      "过滤后完全消失的 genus 数量: 0\n",
      "✅ 过滤后，每个 genus 至少保留 1 条代表性序列。\n",
      "\n",
      "✅ 已保存过滤后的 tokens 到 tokens_filtered.npz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 读取 tokenizer 结果\n",
    "data = np.load(\"tokens.npz\", allow_pickle=True)\n",
    "\n",
    "token_arrays = data[\"token_arrays\"]      # dtype=object, 每条是不定长 token 序列\n",
    "token_lengths = data[\"token_lengths\"]    # 每条的 token 长度\n",
    "feature_ids = data[\"feature_ids\"]        # 和 silva_sub[\"Feature ID\"] 对应\n",
    "genera = data[\"genera\"]                  # 属\n",
    "truncated_flags = data[\"truncated\"]      # 0/1\n",
    "\n",
    "N = len(token_arrays)\n",
    "print(\"总序列数:\", N)\n",
    "print(\"被标记为截断的序列数:\", int(truncated_flags.sum()))\n",
    "\n",
    "# 2. 构造一个 DataFrame，方便分析被截断的序列\n",
    "df = pd.DataFrame({\n",
    "    \"idx\": np.arange(N),\n",
    "    \"FeatureID\": feature_ids,\n",
    "    \"Genus\": genera,\n",
    "    \"TokenLength\": token_lengths,\n",
    "    \"Truncated\": truncated_flags.astype(bool),\n",
    "})\n",
    "\n",
    "trunc_df = df[df[\"Truncated\"]].copy()\n",
    "print(\"\\n=== 所有被截断的序列（共 {} 条） ===\".format(len(trunc_df)))\n",
    "display(trunc_df[[\"idx\", \"Genus\", \"FeatureID\", \"TokenLength\"]])\n",
    "\n",
    "# 3. 每个 Genus 的总序列数（基于当前 26w 条）\n",
    "genus_total_counts = df[\"Genus\"].value_counts()\n",
    "print(\"\\n=== 每个 Genus 的总序列数（前几行预览） ===\")\n",
    "display(genus_total_counts.head())\n",
    "\n",
    "# 4. 决定要删除哪些被截断的序列\n",
    "# 规则：\n",
    "#   - 对于每个 genus：\n",
    "#       * 如果 genus_total_counts[genus] > 截断条数：可以删除该 genus 所有被截断的序列\n",
    "#       * 如果 genus_total_counts[genus] == 截断条数：说明这个 genus 只有这些长序列，\n",
    "#         为了“不让这个 genus 完全消失”，至少保留其中 1 条（保留 token 最短的那条）\n",
    "\n",
    "to_drop_idx = []\n",
    "\n",
    "grouped = trunc_df.groupby(\"Genus\")\n",
    "\n",
    "for genus, group in grouped:\n",
    "    total = genus_total_counts.get(genus, 0)\n",
    "    num_trunc = group.shape[0]\n",
    "\n",
    "    if total > num_trunc:\n",
    "        # 该 genus 还有别的（未截断）代表性序列，所有被截断的都可以安全删除\n",
    "        to_drop_idx.extend(group[\"idx\"].tolist())\n",
    "    else:\n",
    "        # total == num_trunc：所有代表性序列都太长\n",
    "        # 至少保留其中 1 条，这里选择 token 最短的一条保留，其余删除\n",
    "        group_sorted = group.sort_values(\"TokenLength\")\n",
    "        keep_idx = int(group_sorted.iloc[0][\"idx\"])\n",
    "        drop_idxs = [int(i) for i in group_sorted[\"idx\"].tolist() if int(i) != keep_idx]\n",
    "        to_drop_idx.extend(drop_idxs)\n",
    "\n",
    "to_drop_idx = sorted(set(to_drop_idx))\n",
    "\n",
    "print(\"\\n=== 删除计划统计 ===\")\n",
    "print(\"被截断序列总数:           \", len(trunc_df))\n",
    "print(\"计划删除的截断序列条数:   \", len(to_drop_idx))\n",
    "print(\"计划保留但仍被截断的条数: \", len(trunc_df) - len(to_drop_idx))\n",
    "\n",
    "# 5. 看看这些被截断序列分别来自哪些 Genus 以及每个 Genus 的删除情况\n",
    "trunc_df[\"WillDrop\"] = trunc_df[\"idx\"].isin(to_drop_idx)\n",
    "\n",
    "genus_trunc_summary = (\n",
    "    trunc_df\n",
    "    .groupby(\"Genus\")\n",
    "    .agg(\n",
    "        TotalInGenus=(\"Genus\", lambda x: genus_total_counts.loc[x.name]),\n",
    "        TruncCount=(\"Genus\", \"size\"),\n",
    "        DropCount=(\"WillDrop\", \"sum\"),\n",
    "    )\n",
    "    .sort_values(\"TruncCount\", ascending=False)\n",
    ")\n",
    "\n",
    "print(\"\\n=== 各 Genus 的截断情况与删除计划 ===\")\n",
    "display(genus_trunc_summary)\n",
    "\n",
    "# 6. 实际执行过滤，构造保留的 mask\n",
    "keep_mask = np.ones(N, dtype=bool)\n",
    "keep_mask[to_drop_idx] = False\n",
    "\n",
    "print(\"\\n过滤后总序列数:\", int(keep_mask.sum()))\n",
    "\n",
    "# 再检查一遍：过滤之后，每个 genus 是否至少保留 1 条\n",
    "df_filtered = df[keep_mask].copy()\n",
    "genus_filtered_counts = df_filtered[\"Genus\"].value_counts()\n",
    "\n",
    "missing_genus = genus_total_counts.index[~genus_total_counts.index.isin(genus_filtered_counts.index)]\n",
    "print(\"过滤后完全消失的 genus 数量:\", len(missing_genus))\n",
    "\n",
    "if len(missing_genus) > 0:\n",
    "    print(\"⚠ 以下 genus 在过滤后完全没有代表性序列（理论上不应该发生）：\")\n",
    "    display(missing_genus)\n",
    "else:\n",
    "    print(\"✅ 过滤后，每个 genus 至少保留 1 条代表性序列。\")\n",
    "\n",
    "# 7. 保存过滤后的 token 结果，供后续 embedding 使用\n",
    "token_arrays_filtered = token_arrays[keep_mask]\n",
    "token_lengths_filtered = token_lengths[keep_mask]\n",
    "feature_ids_filtered = feature_ids[keep_mask]\n",
    "genera_filtered = genera[keep_mask]\n",
    "truncated_filtered = truncated_flags[keep_mask]\n",
    "\n",
    "np.savez_compressed(\n",
    "    \"tokens_filtered.npz\",\n",
    "    token_arrays=np.array(token_arrays_filtered, dtype=object),\n",
    "    token_lengths=token_lengths_filtered,\n",
    "    feature_ids=feature_ids_filtered,\n",
    "    genera=genera_filtered,\n",
    "    truncated=truncated_filtered\n",
    ")\n",
    "\n",
    "print(\"\\n✅ 已保存过滤后的 tokens 到 tokens_filtered.npz\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88a52e6",
   "metadata": {},
   "source": [
    "## 5. embedding\n",
    "\n",
    "- 对上一步 filtered 后的序列进行 embedding，得到每个序列的 embedding 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cde526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用设备： cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cml_lab/anaconda3/envs/caiqy_DNABERT_S/lib/python3.9/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "/home/cml_lab/anaconda3/envs/caiqy_DNABERT_S/lib/python3.9/site-packages/huggingface_hub/file_download.py:942: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "/home/cml_lab/caiqy/.cache/huggingface/modules/transformers_modules/zhihan1996/DNABERT-S/00e47f96cdea35e4b6f5df89e5419cbe47d490c6/bert_layers.py:126: UserWarning: Unable to import Triton; defaulting MosaicBERT attention implementation to pytorch (this will reduce throughput when using this model).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载 Token 数量: 264903\n",
      "其中标记为 Truncated 的条数: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding: 100%|████████████████████████████████████████████| 4140/4140 [38:09<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding 完成！写入 embeddings.h5\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "# 1. GPU & 模型\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"使用设备：\", device)\n",
    "\n",
    "model = AutoModel.from_pretrained(\n",
    "    \"zhihan1996/DNABERT-S\",\n",
    "    trust_remote_code=True\n",
    ").to(device).eval()\n",
    "\n",
    "\n",
    "\n",
    "# 2. 加载 token 文件，使用过滤后的 tokens_filtered.npz\n",
    "data = np.load(\"tokens_filtered.npz\", allow_pickle=True)\n",
    "token_arrays = data[\"token_arrays\"]      # object array: 每个元素是一条 token 序列（np.array）\n",
    "token_lengths = data[\"token_lengths\"]\n",
    "feature_ids = data[\"feature_ids\"]\n",
    "genera = data[\"genera\"]\n",
    "truncated_flags = data[\"truncated\"]\n",
    "\n",
    "N = len(token_arrays)\n",
    "print(\"加载 Token 数量:\", N)\n",
    "print(\"其中标记为 Truncated 的条数:\", int(truncated_flags.sum()))\n",
    "\n",
    "\n",
    "# 3. 建立 HDF5 文件\n",
    "h5_path = \"embeddings.h5\"\n",
    "h5f = h5py.File(h5_path, \"w\")\n",
    "\n",
    "emb_ds = h5f.create_dataset(\"embeddings\", (N, 768), dtype=\"float32\", compression=\"gzip\")\n",
    "fid_ds = h5f.create_dataset(\"feature_ids\", (N,), dtype=h5py.string_dtype('utf-8'))\n",
    "genus_ds = h5f.create_dataset(\"genus\", (N,), dtype=h5py.string_dtype('utf-8'))\n",
    "trunc_ds = h5f.create_dataset(\"truncated\", (N,), dtype=\"uint8\")\n",
    "\n",
    "\n",
    "\n",
    "# 4. GPU batch embedding（不再 tokenizer）\n",
    "BATCH_SIZE = 128      # A100 上 128 或 256 都可以\n",
    "\n",
    "@torch.no_grad()\n",
    "def embed_batch(token_batch):\n",
    "    # token_batch: list/array of 1D numpy arrays, 每个是一个 token 序列\n",
    "    max_len = max(len(t) for t in token_batch)\n",
    "    padded = np.zeros((len(token_batch), max_len), dtype=np.int64)\n",
    "    for i, t in enumerate(token_batch):\n",
    "        padded[i, :len(t)] = t\n",
    "\n",
    "    tokens = torch.tensor(padded, dtype=torch.long).to(device)\n",
    "    hidden = model(tokens)[0]         # (B, L, 768)\n",
    "    emb = hidden.mean(dim=1)          # (B, 768)\n",
    "    return emb.cpu().numpy().astype(np.float32)\n",
    "\n",
    "\n",
    "\n",
    "# 5. 主循环（GPU 纯 forward）\n",
    "progress = tqdm(range(0, N, BATCH_SIZE), desc=\"Embedding\", dynamic_ncols=True)\n",
    "\n",
    "for start in progress:\n",
    "    end = min(start + BATCH_SIZE, N)\n",
    "\n",
    "    batch_tokens = token_arrays[start:end]\n",
    "    batch_emb = embed_batch(batch_tokens)\n",
    "\n",
    "    emb_ds[start:end] = batch_emb\n",
    "    fid_ds[start:end] = feature_ids[start:end]\n",
    "    genus_ds[start:end] = genera[start:end]\n",
    "    trunc_ds[start:end] = truncated_flags[start:end]\n",
    "\n",
    "h5f.close()\n",
    "\n",
    "print(\"Embedding 完成！写入 embeddings.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb2aee3",
   "metadata": {},
   "source": [
    "## 6. mean pooling\n",
    "\n",
    "- 对上一步得到的每个序列的 embedding 向量进行 mean pooling，得到每个 taxonomic 信息的 embedding 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e01374c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总 embedding 数量: 264903, 维度: 768\n",
      "不同 genus 数量: 1117\n",
      "开始按 genus 聚合 embedding ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1117/1117 [00:00<00:00, 5266.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "聚合完成！\n",
      "最终 genus 数量: 1117\n",
      "✅ genus-level embedding 已保存到 genus_embeddings.npz\n",
      "  - embeddings 形状: (1117, 768)\n",
      "✅ 每个 genus 对应的 embedding 数量统计已保存到 genus_embedding_counts.csv\n",
      "前几行预览：\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genus</th>\n",
       "      <th>NumEmbeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>g__Bacillus</td>\n",
       "      <td>12012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>816</th>\n",
       "      <td>g__Pseudomonas</td>\n",
       "      <td>7070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>g__Streptomyces</td>\n",
       "      <td>5809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>960</th>\n",
       "      <td>g__Streptococcus</td>\n",
       "      <td>4630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>954</th>\n",
       "      <td>g__Staphylococcus</td>\n",
       "      <td>4440</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Genus  NumEmbeddings\n",
       "142        g__Bacillus          12012\n",
       "816     g__Pseudomonas           7070\n",
       "961    g__Streptomyces           5809\n",
       "960   g__Streptococcus           4630\n",
       "954  g__Staphylococcus           4440"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 1. 读取 HDF5 中的 embedding 和 Genus\n",
    "h5_path = \"embeddings.h5\"\n",
    "\n",
    "with h5py.File(h5_path, \"r\") as f:\n",
    "    embeddings = f[\"embeddings\"][...]   # shape: (N, 768)\n",
    "    genera = f[\"genus\"][...]            # h5py string dtype -> numpy array\n",
    "    # 如果类型是 bytes，转成字符串\n",
    "    genera = np.array(genera, dtype=str)\n",
    "\n",
    "N, D = embeddings.shape\n",
    "print(f\"总 embedding 数量: {N}, 维度: {D}\")\n",
    "print(f\"不同 genus 数量: {len(np.unique(genera))}\")\n",
    "\n",
    "\n",
    "# 2. 按 genus 分组，计算平均 embedding\n",
    "# 用 DataFrame 只是为了方便 groupby，不把 embeddings 放进去，避免太大\n",
    "df = pd.DataFrame({\n",
    "    \"Genus\": genera,\n",
    "    \"Idx\": np.arange(N)\n",
    "})\n",
    "\n",
    "groups = df.groupby(\"Genus\")[\"Idx\"].apply(list)\n",
    "\n",
    "genus_list = []\n",
    "genus_emb_list = []\n",
    "genus_counts = []\n",
    "\n",
    "print(\"开始按 genus 聚合 embedding ...\")\n",
    "\n",
    "for genus, idx_list in tqdm(groups.items(), total=len(groups)):\n",
    "    idx_array = np.array(idx_list, dtype=int)\n",
    "    genus_emb = embeddings[idx_array].mean(axis=0)  # (768,)\n",
    "    \n",
    "    genus_list.append(genus)\n",
    "    genus_emb_list.append(genus_emb)\n",
    "    genus_counts.append(len(idx_array))\n",
    "\n",
    "genus_embeddings = np.vstack(genus_emb_list)  # shape: (G, 768)\n",
    "genus_counts = np.array(genus_counts, dtype=np.int32)\n",
    "\n",
    "print(\"聚合完成！\")\n",
    "print(\"最终 genus 数量:\", genus_embeddings.shape[0])\n",
    "\n",
    "\n",
    "# 3. 保存 genus-level embedding（npz）\n",
    "np.savez_compressed(\n",
    "    \"genus_embeddings.npz\",\n",
    "    genus=np.array(genus_list, dtype=object),\n",
    "    embeddings=genus_embeddings,\n",
    "    counts=genus_counts\n",
    ")\n",
    "\n",
    "print(\"✅ genus-level embedding 已保存到 genus_embeddings.npz\")\n",
    "print(\"  - embeddings 形状:\", genus_embeddings.shape)\n",
    "\n",
    "\n",
    "# 4. 输出每个 genus 对应的 embedding 数量统计 CSV\n",
    "genus_stats_df = pd.DataFrame({\n",
    "    \"Genus\": genus_list,\n",
    "    \"NumEmbeddings\": genus_counts\n",
    "}).sort_values(\"NumEmbeddings\", ascending=False)\n",
    "\n",
    "genus_stats_df.to_csv(\"genus_embedding_counts.csv\", index=False)\n",
    "\n",
    "print(\"✅ 每个 genus 对应的 embedding 数量统计已保存到 genus_embedding_counts.csv\")\n",
    "print(\"前几行预览：\")\n",
    "display(genus_stats_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e809d907",
   "metadata": {},
   "source": [
    "## 7.check\n",
    "\n",
    "- 简单查看一下最后输出的 genus_embeddings.npz 文件，看看是否符合预期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "742389a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "包含的数组名称: ['genus', 'embeddings', 'counts', 'explained_variance_ratio']\n",
      "genus 形状: (1117,)\n",
      "embeddings 形状: (1117, 256)\n",
      "counts 形状: (1117,)\n",
      "\n",
      "前 5 个 genus:\n",
      "['g__0319-6G20' 'g__0319-7L14' 'g__11-24' 'g__1174-901-12' 'g__28-YEA-48']\n",
      "\n",
      "前 5 个 genus 的 counts:\n",
      "[362  35 144  61   2]\n",
      "\n",
      "第 1 个 genus 的 embedding 向量前 10 维:\n",
      "[ 0.29121813  0.28034773  0.03950644 -0.14446126 -0.14121476  0.09987964\n",
      " -0.08377898 -0.01667265 -0.00424662 -0.00804974]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = np.load(\"genus_embeddings_256.npz\", allow_pickle=True)\n",
    "\n",
    "print(\"包含的数组名称:\", data.files)\n",
    "\n",
    "genus = data[\"genus\"]\n",
    "embeddings = data[\"embeddings\"]\n",
    "counts = data[\"counts\"]\n",
    "\n",
    "print(\"genus 形状:\", genus.shape)\n",
    "print(\"embeddings 形状:\", embeddings.shape)\n",
    "print(\"counts 形状:\", counts.shape)\n",
    "\n",
    "print(\"\\n前 5 个 genus:\")\n",
    "print(genus[:5])\n",
    "\n",
    "print(\"\\n前 5 个 genus 的 counts:\")\n",
    "print(counts[:5])\n",
    "\n",
    "print(\"\\n第 1 个 genus 的 embedding 向量前 10 维:\")\n",
    "print(embeddings[0][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570cb4aa-5859-4493-aaa6-c94b94ca377e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
