{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3dedfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from pickle import load\n",
    "\n",
    "from transformers import Trainer, GPT2ForSequenceClassification\n",
    "\n",
    "from MiCoGPT.utils.corpus import (\n",
    "    SequenceClassificationDataset,\n",
    ")\n",
    "from MiCoGPT.utils.mgm_utils import eval_and_save\n",
    "\n",
    "from argparse import Namespace\n",
    "from configparser import ConfigParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b39219",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = ConfigParser()\n",
    "cfg.read(\"config.ini\")  # 如果没有可以先跳过或改成其他路径\n",
    "\n",
    "# 手动构造一个等价于命令行的 args 对象\n",
    "args = Namespace(\n",
    "    input=\"../data/try2_withCC/ResMicroDB_90338.pkl\",\n",
    "    model=\"../models/finetuned_model_ResMicroDB_90338\",\n",
    "    output=\"../outputs/predict_ResMicroDB_90338\",\n",
    "    evaluate=True,\n",
    ")\n",
    "\n",
    "args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94e96b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 载入 corpus.pkl\n",
    "corpus = load(open(args.input, \"rb\"))\n",
    "tokenizer = corpus.tokenizer\n",
    "\n",
    "print(\"样本数量（整个 corpus）:\", len(corpus))\n",
    "display(corpus.data.head())\n",
    "\n",
    "meta = corpus.metadata\n",
    "\n",
    "# 如果你的这个 pkl 已经是纯 B 组，其实可以去掉 Split_Group == \"B\" 这一条\n",
    "if \"Split_Group\" in meta.columns:\n",
    "    group_mask = (meta[\"Split_Group\"] == \"B\")\n",
    "else:\n",
    "    # 如果没有这个列，就全 True，当成都属于 B 组\n",
    "    group_mask = pd.Series(True, index=meta.index)\n",
    "\n",
    "if args.evaluate:\n",
    "    # 评估模式：只使用有标签的样本（Is_Healthy 非 NA）\n",
    "    mask = group_mask & meta[\"Is_Healthy\"].notna()\n",
    "    print(\"用于评估的样本数:\", mask.sum())\n",
    "else:\n",
    "    # 仅预测：可以对整个 B 组样本做预测（包括 Is_Healthy 为 NA 的）\n",
    "    mask = group_mask\n",
    "    print(\"用于预测的样本数:\", mask.sum())\n",
    "\n",
    "# 2. 根据 mask 取出样本的行索引（在 corpus.tokens 中的位置）\n",
    "idx = np.where(mask.to_numpy())[0]\n",
    "\n",
    "# 对应样本 ID（用于 y_score.csv 的 index）\n",
    "sample_ids = corpus.data.index[mask]\n",
    "\n",
    "print(\"前几个样本 ID:\", sample_ids[:5])\n",
    "\n",
    "# 3. 准备 input_ids 和 attention_mask\n",
    "input_ids = corpus.tokens[idx]                      # shape: [N_subset, max_len]\n",
    "pad_id = tokenizer.pad_token_id\n",
    "attention_mask = (input_ids != pad_id).long()       # 0/1 tensor\n",
    "\n",
    "# 4. 载入 label encoder（无论是否 evaluate，我们都需要它来确定类别顺序）\n",
    "le = load(open(f\"{args.model}/label_encoder.pkl\", \"rb\"))    \n",
    "num_labels = len(le.categories_[0])\n",
    "print(\"类别数:\", num_labels)\n",
    "print(\"类别名称:\", le.categories_[0])\n",
    "\n",
    "# 5. 构造 labels_tensor\n",
    "if args.evaluate:\n",
    "    # 从 metadata 中提取 Is_Healthy 标签（与 mask 对齐）\n",
    "    labels_series = meta.loc[mask, \"Is_Healthy\"]\n",
    "\n",
    "    # 用训练时的 label encoder 做 transform，保证类别 index 一致\n",
    "    labels_array = le.transform(labels_series.values.reshape(-1, 1)).toarray()\n",
    "    labels_tensor = torch.tensor(labels_array.argmax(axis=1), dtype=torch.long)\n",
    "else:\n",
    "    # 仅预测时，Trainer 不一定需要 labels，这里构建一个 dummy 向量占位即可\n",
    "    labels_tensor = torch.zeros(len(idx), dtype=torch.long)\n",
    "\n",
    "# 6. 构建 SequenceClassificationDataset（用位置参数）\n",
    "dataset = SequenceClassificationDataset(\n",
    "    input_ids,\n",
    "    attention_mask,\n",
    "    labels_tensor,\n",
    ")\n",
    "\n",
    "print(\"Dataset 大小:\", len(dataset))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf203dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里 num_labels 已在上一个 chunk 里计算好了\n",
    "model = GPT2ForSequenceClassification.from_pretrained(\n",
    "    args.model,\n",
    "    num_labels=num_labels,\n",
    ")\n",
    "\n",
    "model.eval()  # 进入 eval 模式\n",
    "\n",
    "trainer = Trainer(model=model)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5d0a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 运行预测\n",
    "predictions = trainer.predict(dataset)\n",
    "\n",
    "# 确保输出目录存在\n",
    "os.makedirs(args.output, exist_ok=True)\n",
    "\n",
    "# 预测得分矩阵（样本数 × 类别数）\n",
    "y_score = predictions.predictions\n",
    "\n",
    "# 保存为 csv，index 对齐我们刚才筛选出的 sample_ids，列名来自 label encoder\n",
    "score_path = os.path.join(args.output, \"y_score.csv\")\n",
    "pd.DataFrame(\n",
    "    y_score,\n",
    "    index=sample_ids,          # 注意：是筛选后的样本 ID 子集\n",
    "    columns=le.categories_[0], # 类别名来自 label encoder\n",
    ").to_csv(score_path)\n",
    "\n",
    "print(\"y_score 已保存到:\", score_path)\n",
    "\n",
    "# 如果需要 evaluation，就计算并保存\n",
    "if args.evaluate:\n",
    "    # Trainer.predict 会把 labels_tensor 作为 label_ids 原样返回\n",
    "    y_true = predictions.label_ids  # shape: [N_subset]\n",
    "    eval_dir = os.path.join(args.output, \"evaluation\")\n",
    "\n",
    "    eval_and_save(\n",
    "        y_score,\n",
    "        y_true,\n",
    "        le.categories_[0],\n",
    "        eval_dir,\n",
    "    )\n",
    "\n",
    "    print(\"evaluation 结果已保存到:\", eval_dir)\n",
    "else:\n",
    "    print(\"只做预测，没有 evaluation。记得根据输出得分设置你自己的阈值或判定规则。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
