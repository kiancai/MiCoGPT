{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5325b9",
   "metadata": {},
   "source": [
    "## 0. 导入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ca57f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pickle import load, dump\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from importlib.resources import files\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "from MiCoGPT.utils.finetune import split_train_val_by_project_stratified_with_labels, prepare_labels_for_subset, load_gpt2_cls_manual, print_gated_stats, FinetuneDataset\n",
    "from configparser import ConfigParser\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e568c13",
   "metadata": {},
   "source": [
    "## 1. 加载 / 设置配置（cfg）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2336c6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[finetune] section:\n",
      "learning_rate = 1e-4\n",
      "warmup_steps = 100\n",
      "weight_decay = 0.001\n",
      "per_device_train_batch_size = 64\n",
      "num_train_epochs = 1000\n",
      "logging_steps = 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Namespace(input='../data/try2_withCC/ResMicroDB_90338.pkl', model='../models/pretrain_ResMicroDB_90338_GATED_base_wte', output='../models/finetuned_ResMicroDB_90338_GATED_base_wte', log='../logs/finetuned_ResMicroDB_90338_GATED_base_wte', val_split=0.2)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_path = \"../MiCoGPT/resources/config.ini\"\n",
    "\n",
    "cfg = ConfigParser()\n",
    "cfg.read(cfg_path)\n",
    "\n",
    "print(\"[finetune] section:\")\n",
    "for k, v in cfg[\"finetune\"].items():\n",
    "    print(f\"{k} = {v}\")\n",
    "\n",
    "input_corpus_path = \"../data/try2_withCC/ResMicroDB_90338.pkl\"\n",
    "pretrained_model_path = \"../models/pretrain_ResMicroDB_90338_GATED_base_wte\"\n",
    "output_model_dir  = \"../models/finetuned_ResMicroDB_90338_GATED_base_wte\"\n",
    "log_dir           = \"../logs/finetuned_ResMicroDB_90338_GATED_base_wte\"\n",
    "val_split         = 0.2         # 验证集比例\n",
    "\n",
    "args = Namespace(\n",
    "    input=input_corpus_path,\n",
    "    model=pretrained_model_path,\n",
    "    output=output_model_dir,\n",
    "    log=log_dir,\n",
    "    val_split=val_split,\n",
    ")\n",
    "\n",
    "args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c692e",
   "metadata": {},
   "source": [
    "## 加载语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b01b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in all_corpus: 90338\n",
      "Number of samples in finetune_subset: 55575\n",
      "Split_Group\n",
      "A    74557\n",
      "B    13901\n",
      "C     1880\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "all_corpus = load(open(args.input, \"rb\"))\n",
    "tokenizer = all_corpus.tokenizer\n",
    "\n",
    "# 你想作为微调集合的样本（例：Split_Group == \"A\" 且 Is_Healthy 非空）\n",
    "finetune_subset = all_corpus.subset_by_metadata(\n",
    "    lambda df: (df[\"Split_Group\"] == \"A\") & df[\"Is_Healthy\"].notna()\n",
    ")\n",
    "\n",
    "print(\"Number of samples in all_corpus:\", len(all_corpus))\n",
    "print(\"Number of samples in finetune_subset:\", len(finetune_subset))\n",
    "print(all_corpus.metadata[\"Split_Group\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936d151",
   "metadata": {},
   "source": [
    "## 生成标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28563458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[labels] subset size=55575\n",
      "[labels] num_labels=2\n",
      "[labels] distribution:\n",
      "0    31073\n",
      "1    24502\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labels_tensor, all_labels, le, num_labels = prepare_labels_for_subset(\n",
    "    all_corpus=all_corpus,\n",
    "    subset=finetune_subset,\n",
    "    label_col=\"Is_Healthy\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b01364ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load:vanilla] missing_keys=1, unexpected_keys=1\n",
      "missing keys: ['score.weight']\n",
      "unexpected keys: ['lm_head.weight']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(1121, 256)\n",
       "    (wpe): Embedding(512, 256)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-7): 8 x GPT2Block(\n",
       "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=256, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODE = \"vanilla\"   # 或者 \"vanilla\"/\"gated\"\n",
    "\n",
    "npz_path = files(\"MiCoGPT\") / \"resources\" / \"genus_embeddings_256.npz\"\n",
    "\n",
    "model, device = load_gpt2_cls_manual(\n",
    "    model_dir=args.model,\n",
    "    num_labels=num_labels,\n",
    "    mode=MODE,\n",
    "    tokenizer=tokenizer if MODE == \"gated\" else None,\n",
    "    npz_path=npz_path if MODE == \"gated\" else None,\n",
    "    g_min=0.0,\n",
    "    init_w=0.1,\n",
    ")\n",
    "model.train()\n",
    "if MODE == \"gated\":\n",
    "    print_gated_stats(model, tokenizer=tokenizer, npz_path=npz_path)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e637dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=True,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=epoch,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=False,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=every_save,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=0.0001,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=../logs/finetuned_ResMicroDB_90338_GATED_base_wte,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=5,\n",
       "logging_strategy=steps,\n",
       "lr_scheduler_type=linear,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=eval_loss,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=1000,\n",
       "optim=adamw_torch,\n",
       "optim_args=None,\n",
       "output_dir=../logs/finetuned_ResMicroDB_90338_GATED_base_wte/finetune_checkpoints,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=64,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=../logs/finetuned_ResMicroDB_90338_GATED_base_wte/finetune_checkpoints,\n",
       "save_on_each_node=False,\n",
       "save_safetensors=False,\n",
       "save_steps=500,\n",
       "save_strategy=epoch,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=100,\n",
       "weight_decay=0.001,\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args_dict = {\n",
    "    \"learning_rate\": cfg.getfloat(\"finetune\", \"learning_rate\"),\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"group_by_length\": False,\n",
    "    # \"length_column_name\": \"length\",\n",
    "    \"disable_tqdm\": False,\n",
    "    \"lr_scheduler_type\": \"linear\",\n",
    "    \"warmup_steps\": cfg.getint(\"finetune\", \"warmup_steps\"),\n",
    "    \"weight_decay\": cfg.getfloat(\"finetune\", \"weight_decay\"),\n",
    "    \"per_device_train_batch_size\": cfg.getint(\"finetune\", \"per_device_train_batch_size\"),\n",
    "    \"num_train_epochs\": cfg.getint(\"finetune\", \"num_train_epochs\"),\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"logging_steps\": cfg.getint(\"finetune\", \"logging_steps\"),\n",
    "    \"output_dir\": f\"{args.log}/finetune_checkpoints\",\n",
    "    \"logging_dir\": args.log,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"metric_for_best_model\": \"eval_loss\",\n",
    "    \"greater_is_better\": False,\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(**training_args_dict)\n",
    "training_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f8d1b5",
   "metadata": {},
   "source": [
    "## 划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a629708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[split] total_samples=55575, target_val~11115\n",
      "[split] eligible_projects=251, eligible_samples=55398\n",
      "[split] ineligible_projects=16, ineligible_samples=177\n",
      "[split] label_dist (overall):\n",
      "Is_Healthy\n",
      "False    31073\n",
      "True     24502\n",
      "Name: count, dtype: int64\n",
      "[split] actual_val=11115 (target~11115), train=44460\n",
      "[split] label_dist (val):\n",
      "Is_Healthy\n",
      "False    6109\n",
      "True     5006\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_subset, val_subset = split_train_val_by_project_stratified_with_labels(\n",
    "    finetune_subset,\n",
    "    label_col=\"Is_Healthy\",\n",
    "    project_col=\"Project_ID\",\n",
    "    val_ratio=args.val_split,\n",
    "    min_project_samples=20,\n",
    "    min_val_per_project=2,\n",
    "    random_state=42,\n",
    "    label_balance_strength=1.0,  # 先用 1.0；想更强拉平就 2.0；不管标签就 0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4157a3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9035' max='695000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  9035/695000 47:51 < 60:34:35, 3.15 it/s, Epoch 13/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.185800</td>\n",
       "      <td>0.180386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.141716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>0.135808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.143015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.148840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.051400</td>\n",
       "      <td>0.152337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.166463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.016900</td>\n",
       "      <td>0.195642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.062800</td>\n",
       "      <td>0.204726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.231673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.012300</td>\n",
       "      <td>0.238283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.247136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.260774</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and label encoder saved to: ../models/finetuned_ResMicroDB_90338_GATED_base_wte\n",
      "Training logs saved to: ../logs/finetuned_ResMicroDB_90338_GATED_base_wte/finetune_log.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>12.99</td>\n",
       "      <td>9025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>12.99</td>\n",
       "      <td>9030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>13.00</td>\n",
       "      <td>9035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1819</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.00</td>\n",
       "      <td>9035</td>\n",
       "      <td>0.260774</td>\n",
       "      <td>18.8849</td>\n",
       "      <td>588.565</td>\n",
       "      <td>73.604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1820</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.00</td>\n",
       "      <td>9035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2873.3149</td>\n",
       "      <td>15473.417</td>\n",
       "      <td>241.881</td>\n",
       "      <td>1.121991e+16</td>\n",
       "      <td>0.069355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  learning_rate  epoch  step  eval_loss  eval_runtime  \\\n",
       "1816  0.0057       0.000099  12.99  9025        NaN           NaN   \n",
       "1817  0.0258       0.000099  12.99  9030        NaN           NaN   \n",
       "1818  0.0022       0.000099  13.00  9035        NaN           NaN   \n",
       "1819     NaN            NaN  13.00  9035   0.260774       18.8849   \n",
       "1820     NaN            NaN  13.00  9035        NaN           NaN   \n",
       "\n",
       "      eval_samples_per_second  eval_steps_per_second  train_runtime  \\\n",
       "1816                      NaN                    NaN            NaN   \n",
       "1817                      NaN                    NaN            NaN   \n",
       "1818                      NaN                    NaN            NaN   \n",
       "1819                  588.565                 73.604            NaN   \n",
       "1820                      NaN                    NaN      2873.3149   \n",
       "\n",
       "      train_samples_per_second  train_steps_per_second    total_flos  \\\n",
       "1816                       NaN                     NaN           NaN   \n",
       "1817                       NaN                     NaN           NaN   \n",
       "1818                       NaN                     NaN           NaN   \n",
       "1819                       NaN                     NaN           NaN   \n",
       "1820                 15473.417                 241.881  1.121991e+16   \n",
       "\n",
       "      train_loss  \n",
       "1816         NaN  \n",
       "1817         NaN  \n",
       "1818         NaN  \n",
       "1819         NaN  \n",
       "1820    0.069355  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Start training...\")\n",
    "\n",
    "train_idx = np.array(train_subset.indices)\n",
    "val_idx   = np.array(val_subset.indices)\n",
    "\n",
    "train_labels = all_labels[train_idx]\n",
    "val_labels   = all_labels[val_idx]\n",
    "assert (train_labels != -1).all()\n",
    "assert (val_labels != -1).all()\n",
    "\n",
    "train_dataset = FinetuneDataset(all_corpus, train_idx, train_labels)\n",
    "val_dataset   = FinetuneDataset(all_corpus, val_idx, val_labels)\n",
    "\n",
    "callbacks = [EarlyStoppingCallback(early_stopping_patience=10)]\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 保存模型\n",
    "os.makedirs(args.output, exist_ok=True)\n",
    "trainer.save_model(args.output)\n",
    "\n",
    "# 保存 label encoder\n",
    "dump(le, open(os.path.join(args.output, \"label_encoder.pkl\"), \"wb\"))\n",
    "print(f\"Model and label encoder saved to: {args.output}\")\n",
    "\n",
    "# 保存日志\n",
    "logs = trainer.state.log_history\n",
    "logs_df = pd.DataFrame(logs)\n",
    "\n",
    "os.makedirs(args.log, exist_ok=True)\n",
    "log_path = os.path.join(args.log, \"finetune_log.csv\")\n",
    "logs_df.to_csv(log_path, index=False)\n",
    "\n",
    "print(f\"Training logs saved to: {log_path}\")\n",
    "logs_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9cf15-1adc-478d-92d6-9debf2e9a32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (caiqy_MiCoSeq_dev)",
   "language": "python",
   "name": "caiqy_micoseq_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
