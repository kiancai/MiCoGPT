{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5325b9",
   "metadata": {},
   "source": [
    "## 0. 导入依赖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ca57f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pickle import load, dump\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "from importlib.resources import files\n",
    "from transformers.trainer_callback import EarlyStoppingCallback\n",
    "from MiCoGPT.utils.finetune import split_train_val_by_project_stratified_with_labels, prepare_labels_for_subset, load_gpt2_cls_manual, print_gated_stats, FinetuneDataset\n",
    "from configparser import ConfigParser\n",
    "from argparse import Namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e568c13",
   "metadata": {},
   "source": [
    "## 1. 加载 / 设置配置（cfg）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2336c6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[finetune] section:\n",
      "learning_rate = 1e-5\n",
      "warmup_steps = 100\n",
      "weight_decay = 0.001\n",
      "per_device_train_batch_size = 64\n",
      "num_train_epochs = 1000\n",
      "logging_steps = 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Namespace(input='../data/try2_withCC/ResMicroDB_90338.pkl', model='../models/pretrain_ResMicroDB_90338_GATED_base_wte', output='../models/finetuned_ResMicroDB_90338_GATED_base_wte_lowRate', log='../logs/finetuned_ResMicroDB_90338_GATED_base_wte_lowRate', val_split=0.2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_path = \"../MiCoGPT/resources/config.ini\"\n",
    "\n",
    "cfg = ConfigParser()\n",
    "cfg.read(cfg_path)\n",
    "\n",
    "print(\"[finetune] section:\")\n",
    "for k, v in cfg[\"finetune\"].items():\n",
    "    print(f\"{k} = {v}\")\n",
    "\n",
    "input_corpus_path = \"../data/try2_withCC/ResMicroDB_90338.pkl\"\n",
    "pretrained_model_path = \"../models/pretrain_ResMicroDB_90338_GATED_base_wte\"\n",
    "output_model_dir  = \"../models/finetuned_ResMicroDB_90338_GATED_base_wte_lowRate\"\n",
    "log_dir           = \"../logs/finetuned_ResMicroDB_90338_GATED_base_wte_lowRate\"\n",
    "val_split         = 0.2         # 验证集比例\n",
    "\n",
    "args = Namespace(\n",
    "    input=input_corpus_path,\n",
    "    model=pretrained_model_path,\n",
    "    output=output_model_dir,\n",
    "    log=log_dir,\n",
    "    val_split=val_split,\n",
    ")\n",
    "\n",
    "args\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724c692e",
   "metadata": {},
   "source": [
    "## 加载语料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21b01b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in all_corpus: 90338\n",
      "Number of samples in finetune_subset: 55575\n",
      "Split_Group\n",
      "A    74557\n",
      "B    13901\n",
      "C     1880\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "all_corpus = load(open(args.input, \"rb\"))\n",
    "tokenizer = all_corpus.tokenizer\n",
    "\n",
    "# 你想作为微调集合的样本（例：Split_Group == \"A\" 且 Is_Healthy 非空）\n",
    "finetune_subset = all_corpus.subset_by_metadata(\n",
    "    lambda df: (df[\"Split_Group\"] == \"A\") & df[\"Is_Healthy\"].notna()\n",
    ")\n",
    "\n",
    "print(\"Number of samples in all_corpus:\", len(all_corpus))\n",
    "print(\"Number of samples in finetune_subset:\", len(finetune_subset))\n",
    "print(all_corpus.metadata[\"Split_Group\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1936d151",
   "metadata": {},
   "source": [
    "## 生成标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28563458",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[labels] subset size=55575\n",
      "[labels] num_labels=2\n",
      "[labels] distribution:\n",
      "0    31073\n",
      "1    24502\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "labels_tensor, all_labels, le, num_labels = prepare_labels_for_subset(\n",
    "    all_corpus=all_corpus,\n",
    "    subset=finetune_subset,\n",
    "    label_col=\"Is_Healthy\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b01364ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load:vanilla] missing_keys=1, unexpected_keys=1\n",
      "missing keys: ['score.weight']\n",
      "unexpected keys: ['lm_head.weight']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPT2ForSequenceClassification(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(1121, 256)\n",
       "    (wpe): Embedding(512, 256)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-7): 8 x GPT2Block(\n",
       "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (score): Linear(in_features=256, out_features=2, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODE = \"vanilla\"   # 或者 \"vanilla\"/\"gated\"\n",
    "\n",
    "npz_path = files(\"MiCoGPT\") / \"resources\" / \"genus_embeddings_256.npz\"\n",
    "\n",
    "model, device = load_gpt2_cls_manual(\n",
    "    model_dir=args.model,\n",
    "    num_labels=num_labels,\n",
    "    mode=MODE,\n",
    "    tokenizer=tokenizer if MODE == \"gated\" else None,\n",
    "    npz_path=npz_path if MODE == \"gated\" else None,\n",
    "    g_min=0.0,\n",
    "    init_w=0.1,\n",
    ")\n",
    "model.train()\n",
    "if MODE == \"gated\":\n",
    "    print_gated_stats(model, tokenizer=tokenizer, npz_path=npz_path)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e637dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArguments(\n",
       "_n_gpu=1,\n",
       "adafactor=False,\n",
       "adam_beta1=0.9,\n",
       "adam_beta2=0.999,\n",
       "adam_epsilon=1e-08,\n",
       "auto_find_batch_size=False,\n",
       "bf16=False,\n",
       "bf16_full_eval=False,\n",
       "data_seed=None,\n",
       "dataloader_drop_last=False,\n",
       "dataloader_num_workers=0,\n",
       "dataloader_pin_memory=True,\n",
       "ddp_backend=None,\n",
       "ddp_broadcast_buffers=None,\n",
       "ddp_bucket_cap_mb=None,\n",
       "ddp_find_unused_parameters=None,\n",
       "ddp_timeout=1800,\n",
       "debug=[],\n",
       "deepspeed=None,\n",
       "disable_tqdm=False,\n",
       "dispatch_batches=None,\n",
       "do_eval=True,\n",
       "do_predict=False,\n",
       "do_train=True,\n",
       "eval_accumulation_steps=None,\n",
       "eval_delay=0,\n",
       "eval_steps=None,\n",
       "evaluation_strategy=epoch,\n",
       "fp16=False,\n",
       "fp16_backend=auto,\n",
       "fp16_full_eval=False,\n",
       "fp16_opt_level=O1,\n",
       "fsdp=[],\n",
       "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
       "fsdp_min_num_params=0,\n",
       "fsdp_transformer_layer_cls_to_wrap=None,\n",
       "full_determinism=False,\n",
       "gradient_accumulation_steps=1,\n",
       "gradient_checkpointing=False,\n",
       "greater_is_better=False,\n",
       "group_by_length=False,\n",
       "half_precision_backend=auto,\n",
       "hub_always_push=False,\n",
       "hub_model_id=None,\n",
       "hub_private_repo=False,\n",
       "hub_strategy=every_save,\n",
       "hub_token=<HUB_TOKEN>,\n",
       "ignore_data_skip=False,\n",
       "include_inputs_for_metrics=False,\n",
       "jit_mode_eval=False,\n",
       "label_names=None,\n",
       "label_smoothing_factor=0.0,\n",
       "learning_rate=1e-05,\n",
       "length_column_name=length,\n",
       "load_best_model_at_end=True,\n",
       "local_rank=0,\n",
       "log_level=passive,\n",
       "log_level_replica=warning,\n",
       "log_on_each_node=True,\n",
       "logging_dir=../logs/finetuned_ResMicroDB_90338_GATED_base_wte_lowRate,\n",
       "logging_first_step=False,\n",
       "logging_nan_inf_filter=True,\n",
       "logging_steps=5,\n",
       "logging_strategy=steps,\n",
       "lr_scheduler_type=linear,\n",
       "max_grad_norm=1.0,\n",
       "max_steps=-1,\n",
       "metric_for_best_model=eval_loss,\n",
       "mp_parameters=,\n",
       "no_cuda=False,\n",
       "num_train_epochs=1000,\n",
       "optim=adamw_torch,\n",
       "optim_args=None,\n",
       "output_dir=../logs/finetuned_ResMicroDB_90338_GATED_base_wte_lowRate/finetune_checkpoints,\n",
       "overwrite_output_dir=False,\n",
       "past_index=-1,\n",
       "per_device_eval_batch_size=8,\n",
       "per_device_train_batch_size=64,\n",
       "prediction_loss_only=False,\n",
       "push_to_hub=False,\n",
       "push_to_hub_model_id=None,\n",
       "push_to_hub_organization=None,\n",
       "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
       "ray_scope=last,\n",
       "remove_unused_columns=True,\n",
       "report_to=[],\n",
       "resume_from_checkpoint=None,\n",
       "run_name=../logs/finetuned_ResMicroDB_90338_GATED_base_wte_lowRate/finetune_checkpoints,\n",
       "save_on_each_node=False,\n",
       "save_safetensors=False,\n",
       "save_steps=500,\n",
       "save_strategy=epoch,\n",
       "save_total_limit=None,\n",
       "seed=42,\n",
       "sharded_ddp=[],\n",
       "skip_memory_metrics=True,\n",
       "tf32=None,\n",
       "torch_compile=False,\n",
       "torch_compile_backend=None,\n",
       "torch_compile_mode=None,\n",
       "torchdynamo=None,\n",
       "tpu_metrics_debug=False,\n",
       "tpu_num_cores=None,\n",
       "use_cpu=False,\n",
       "use_ipex=False,\n",
       "use_legacy_prediction_loop=False,\n",
       "use_mps_device=False,\n",
       "warmup_ratio=0.0,\n",
       "warmup_steps=100,\n",
       "weight_decay=0.001,\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args_dict = {\n",
    "    \"learning_rate\": cfg.getfloat(\"finetune\", \"learning_rate\"),\n",
    "    \"do_train\": True,\n",
    "    \"do_eval\": True,\n",
    "    \"group_by_length\": False,\n",
    "    # \"length_column_name\": \"length\",\n",
    "    \"disable_tqdm\": False,\n",
    "    \"lr_scheduler_type\": \"linear\",\n",
    "    \"warmup_steps\": cfg.getint(\"finetune\", \"warmup_steps\"),\n",
    "    \"weight_decay\": cfg.getfloat(\"finetune\", \"weight_decay\"),\n",
    "    \"per_device_train_batch_size\": cfg.getint(\"finetune\", \"per_device_train_batch_size\"),\n",
    "    \"num_train_epochs\": cfg.getint(\"finetune\", \"num_train_epochs\"),\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"logging_steps\": cfg.getint(\"finetune\", \"logging_steps\"),\n",
    "    \"output_dir\": f\"{args.log}/finetune_checkpoints\",\n",
    "    \"logging_dir\": args.log,\n",
    "    \"load_best_model_at_end\": True,\n",
    "    \"metric_for_best_model\": \"eval_loss\",\n",
    "    \"greater_is_better\": False,\n",
    "}\n",
    "\n",
    "training_args = TrainingArguments(**training_args_dict)\n",
    "training_args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f8d1b5",
   "metadata": {},
   "source": [
    "## 划分训练集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a629708f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[split] total_samples=55575, target_val~11115\n",
      "[split] eligible_projects=251, eligible_samples=55398\n",
      "[split] ineligible_projects=16, ineligible_samples=177\n",
      "[split] label_dist (overall):\n",
      "Is_Healthy\n",
      "False    31073\n",
      "True     24502\n",
      "Name: count, dtype: int64\n",
      "[split] actual_val=11115 (target~11115), train=44460\n",
      "[split] label_dist (val):\n",
      "Is_Healthy\n",
      "False    6109\n",
      "True     5006\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_subset, val_subset = split_train_val_by_project_stratified_with_labels(\n",
    "    finetune_subset,\n",
    "    label_col=\"Is_Healthy\",\n",
    "    project_col=\"Project_ID\",\n",
    "    val_ratio=args.val_split,\n",
    "    min_project_samples=20,\n",
    "    min_val_per_project=2,\n",
    "    random_state=42,\n",
    "    label_balance_strength=1.0,  # 先用 1.0；想更强拉平就 2.0；不管标签就 0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4157a3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22935' max='695000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 22935/695000 2:01:58 < 59:34:22, 3.13 it/s, Epoch 33/1000]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.427000</td>\n",
       "      <td>0.396693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.326600</td>\n",
       "      <td>0.307771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.291900</td>\n",
       "      <td>0.262569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.201300</td>\n",
       "      <td>0.235621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.215500</td>\n",
       "      <td>0.219621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.174400</td>\n",
       "      <td>0.205769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>0.194343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.229700</td>\n",
       "      <td>0.186795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.163300</td>\n",
       "      <td>0.180600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.177100</td>\n",
       "      <td>0.175076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.170065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>0.166302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.133600</td>\n",
       "      <td>0.162681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.122500</td>\n",
       "      <td>0.159807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.141900</td>\n",
       "      <td>0.158099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.155080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.136700</td>\n",
       "      <td>0.153679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>0.153080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.114100</td>\n",
       "      <td>0.152094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.151625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.098700</td>\n",
       "      <td>0.151802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.151119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.076400</td>\n",
       "      <td>0.151118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.108100</td>\n",
       "      <td>0.152180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.152716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.069500</td>\n",
       "      <td>0.153349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.153747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.155634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.156825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.092300</td>\n",
       "      <td>0.157102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>0.159176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>0.159958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.070500</td>\n",
       "      <td>0.161328</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n",
      "/home/cml_lab/caiqy/project/MiCoGPT/MiCoGPT/utils/corpus.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {'input_ids': torch.tensor(tokens),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and label encoder saved to: ../models/finetuned_ResMicroDB_90338_GATED_base_wte_lowRate\n",
      "Training logs saved to: ../logs/finetuned_ResMicroDB_90338_GATED_base_wte_lowRate/finetune_log.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>epoch</th>\n",
       "      <th>step</th>\n",
       "      <th>eval_loss</th>\n",
       "      <th>eval_runtime</th>\n",
       "      <th>eval_samples_per_second</th>\n",
       "      <th>eval_steps_per_second</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "      <th>total_flos</th>\n",
       "      <th>train_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4616</th>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>32.99</td>\n",
       "      <td>22925</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4617</th>\n",
       "      <td>0.0708</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>32.99</td>\n",
       "      <td>22930</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4618</th>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>33.00</td>\n",
       "      <td>22935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4619</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.00</td>\n",
       "      <td>22935</td>\n",
       "      <td>0.161328</td>\n",
       "      <td>18.7799</td>\n",
       "      <td>591.857</td>\n",
       "      <td>74.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4620</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.00</td>\n",
       "      <td>22935</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7319.6988</td>\n",
       "      <td>6074.02</td>\n",
       "      <td>94.949</td>\n",
       "      <td>2.848132e+16</td>\n",
       "      <td>0.149825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  learning_rate  epoch   step  eval_loss  eval_runtime  \\\n",
       "4616  0.0505        0.00001  32.99  22925        NaN           NaN   \n",
       "4617  0.0708        0.00001  32.99  22930        NaN           NaN   \n",
       "4618  0.0705        0.00001  33.00  22935        NaN           NaN   \n",
       "4619     NaN            NaN  33.00  22935   0.161328       18.7799   \n",
       "4620     NaN            NaN  33.00  22935        NaN           NaN   \n",
       "\n",
       "      eval_samples_per_second  eval_steps_per_second  train_runtime  \\\n",
       "4616                      NaN                    NaN            NaN   \n",
       "4617                      NaN                    NaN            NaN   \n",
       "4618                      NaN                    NaN            NaN   \n",
       "4619                  591.857                 74.015            NaN   \n",
       "4620                      NaN                    NaN      7319.6988   \n",
       "\n",
       "      train_samples_per_second  train_steps_per_second    total_flos  \\\n",
       "4616                       NaN                     NaN           NaN   \n",
       "4617                       NaN                     NaN           NaN   \n",
       "4618                       NaN                     NaN           NaN   \n",
       "4619                       NaN                     NaN           NaN   \n",
       "4620                   6074.02                  94.949  2.848132e+16   \n",
       "\n",
       "      train_loss  \n",
       "4616         NaN  \n",
       "4617         NaN  \n",
       "4618         NaN  \n",
       "4619         NaN  \n",
       "4620    0.149825  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Start training...\")\n",
    "\n",
    "train_idx = np.array(train_subset.indices)\n",
    "val_idx   = np.array(val_subset.indices)\n",
    "\n",
    "train_labels = all_labels[train_idx]\n",
    "val_labels   = all_labels[val_idx]\n",
    "assert (train_labels != -1).all()\n",
    "assert (val_labels != -1).all()\n",
    "\n",
    "train_dataset = FinetuneDataset(all_corpus, train_idx, train_labels)\n",
    "val_dataset   = FinetuneDataset(all_corpus, val_idx, val_labels)\n",
    "\n",
    "callbacks = [EarlyStoppingCallback(early_stopping_patience=5)]\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "# 保存模型\n",
    "os.makedirs(args.output, exist_ok=True)\n",
    "trainer.save_model(args.output)\n",
    "\n",
    "# 保存 label encoder\n",
    "dump(le, open(os.path.join(args.output, \"label_encoder.pkl\"), \"wb\"))\n",
    "print(f\"Model and label encoder saved to: {args.output}\")\n",
    "\n",
    "# 保存日志\n",
    "logs = trainer.state.log_history\n",
    "logs_df = pd.DataFrame(logs)\n",
    "\n",
    "os.makedirs(args.log, exist_ok=True)\n",
    "log_path = os.path.join(args.log, \"finetune_log.csv\")\n",
    "logs_df.to_csv(log_path, index=False)\n",
    "\n",
    "print(f\"Training logs saved to: {log_path}\")\n",
    "logs_df.tail()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9cf15-1adc-478d-92d6-9debf2e9a32f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (caiqy_MiCoSeq_dev)",
   "language": "python",
   "name": "caiqy_micoseq_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
